<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <!-- <title>DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies</title> -->
    <title>DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies</title>
    <link rel="icon" type="image/png" sizes="32x32" href="img/icon.png">

    <meta name="description" content="DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <meta property="og:image" content="https://deligrasp.github.io/img/dg_teaser.png">
    <meta property="og:image:type" content="image/jpeg">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://deligrasp.github.io/"/>
    <meta property="og:title" content="DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies" />
    <meta property="og:description" content="Project page for DeliGrasp." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies" />
    <meta name="twitter:description" content="Project page for DeliGrasp." />
    <meta name="twitter:image" content="https://deligrasp.github.io/img/dg_teaser.png" />

<!-- progprompt -->
<script>
    function updateSingleVideo() {
      var demo = document.getElementById("single-menu-demos").value;
      var task = document.getElementById("single-menu-tasks").value;
      var inst = document.getElementById("single-menu-instances").value;

      console.log("single", demo, task, inst)

      var video = document.getElementById("multi-task-result-video");
      video.src = "media/results/sim_rollouts/" + 
                  "n" +
                  demo +
                  "-" +
                  task +
                  "-" +
                  inst +
                  ".mp4"
      video.playbackRate = 1.75;
      video.play();
    }

    function updateQpredVideo() {
      var task = document.getElementById("single-menu-qpred").value;

      console.log("qpred", task)

      var video = document.getElementById("q-pred-video");
      video.src = "media/results/qpred/" + 
                  task + 
                  ".mp4"
      video.playbackRate = 1.75;
      video.play();
    }

  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
<!--  -->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script>hljs.highlightAll();</script>

  
    <script src="js/app.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=GTM-TKNZC2XQ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'GTM-TKNZC2XQ');
    </script>
    <script>
    document.addEventListener('DOMContentLoaded', function () {
        // remove dropdown duplicates: https://stackoverflow.com/questions/23729456/how-to-remove-duplicate-dropdown-option-elements-with-same-value
        $(".select option").each(function() {
        $(this).siblings('[value="'+ this.value +'"]').remove();
        });

        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
            content.style.display = "none";
            } else {
            content.style.display = "block";
            }
        });
        }
    }, false);
    </script>
    <style>
        .nav-pills {
            position: relative;
            display: inline;
        }

        .imtip {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <strong><span style="font-variant: small-caps;"><font size="+4">DeliGrasp: </font></span>
                </strong>
                <strong>
                    <!-- <font size="+4">Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies</font> -->
                    <font size="+4">Inferring Object Properties with LLMs for Adaptive Grasp Policies</font>
                </strong>
                <!--<small>
                    CoRL 2024
                </small>-->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <br>
                    <li>William Xie <span class="icon">
                        <a href="mailto:wixi6454@colorado.edu"><i class="fa fa-envelope"></i></a>,
                      </span></li>
                    <li>Maria Valentini</li>
                    <li>Jensen Lavering</li>
                    <li>Nikolaus Correll</li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12 text-center">                
                <strong>University of Colorado at Boulder</strong>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">                
                <small>
                    CoRL 2024
                </small>
            </div>
        </div>

        
    <!-- container break -->
    </div>

    <div class="row"> <div class="col text-center">
    <section class="hero">
        <div class="hero-body" style="padding: 10px">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="publication-links">
                    <span class="link-block">
                        <a target="_blank" href="assets/dg.pdf"
                           class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                              <i class="fas fa-file-pdf"></i>
                          </span>
                          <span>Paper</span>
                        </a>
                      </span>

                    <span class="link-block">
                      <a target="_blank" href="https://arxiv.org/abs/2403.07832"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>
      
                  <span class="link-block">
                    <a target="_blank" href="https://github.com/deligrasp/deligrasp"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                      </a>
                  </span>
      
                  <span class="link-block">
                    <a href="#faqs"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fas fa-question"></i>
                      </span>
                      <span>FAQs</span>
                      </a>
                  </span>  

                  <span class="link-block">
                    <a target="_blank" href="https://youtu.be/gcEFXVynbAs"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                      </a>
                  </span>

                </div>
            </div>
          </div>
        </div>
    </section>
    </div></div>
      
<!-- coming soon
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="600" height="300" src="https://youtu.be/gcEFXVynbAs"
                            title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                            allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->

<div class="container">
<div class="row" id="demo">
<div class="col-md-1"></div>
<div class="col-md-10 col-xs-12">
<div class="row">
    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
        <img src="videos/01_plane.png" width="100%"
            alt=" User instruction: Pick up the paper airplane. 
[sep]'''
Estimated characteristics:
m: 5.0g
µ: 0.5
k: 20.0 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 30.0
initial_force = slip_threshold = 0.098 
additional_closure = 2.0
additional_force_increase = 0.01
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)

## k: 184.9 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/02_empty-cup.png" width="100%"
                            alt="User instruction: Pick up the empty paper cup.
[sep]'''
Estimated characteristics:
m: 10g
µ: 0.4
k: 50.0 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 75.0
initial_force = slip_threshold = 0.025
additional_closure = 5.0
additional_force_increase = 0.025
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 389.8 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/03_yuba.png" width="100%"
                            alt="User instruction: Pick up the yuba (dried tofu skin).
[sep]'''
Estimated characteristics:
m: 20g
µ: 0.5
k: 200 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 25.0
initial_force = slip_threshold = 0.025
additional_closure = 2.0
additional_force_increase = 0.04
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 157.7 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/04_raspberry.png" width="100%"
                            alt=" User instruction: Pick up the raspberry. 
[sep]'''
Estimated characteristics:
m: 5.0g
µ: 0.8
k: 50.0 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 18.0
initial_force = slip_threshold = 0.0625
additional_closure = 1.0
additional_force_increase = 0.01
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 61.0 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/05_taco.png" width="100%" 
                            alt="User instruction: Pick up the hard-shell tortilla.
[sep]'''
Estimated characteristics:
m: 50g
µ: 0.5
k: 1000 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 65.0
initial_force = slip_threshold = 0.98
additional_closure = 2.0
additional_force_increase = 0.2
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 188.4 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/06_mandarin.png" width="100%"
                            alt="User instruction: Pick up the mandarin.
[sep]'''
Estimated characteristics:
m: 150g
µ: 0.8
k: 500 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 50.0
initial_force = slip_threshold = 1.88
additional_closure = 2.0
additional_force_increase = 0.1
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 151.8 N/m"
                            onclick="populateDemo(this);">
                    </div>
                </div>

                <p></p>

<div class="row border rounded" style="padding-top:10px; padding-bottom:10px;">
    <div class="col-md-6">
        <video width="100%" height="100%" id="demo-video" autoplay loop muted webkit-playsinline playsinline onclick="setAttribute('controls', 'true');">
            <source id="expandedImg" src="videos/DeliGrasp.mp4" type="video/mp4">
        </video>

    </div>
    <div class="col-md-6">
        <div id="imgtext">Prompt text in gray.</div>
        <div>
            <pre><code class="language-python" id="answer">DG policy shown within code block.</code></pre>
        </div>
    </div>
</div>
                <p></p>
                <div class="row">
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/07_stuffed_animal.png" width="100%"
                            alt=" User instruction: Pick up the tail of the stuffed animal.
[sep]'''
Estimated characteristics:
m: 50g
µ: 0.8
k: 100 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 25.0
initial_force = slip_threshold = 0.61
additional_closure = 2.0
additional_force_increase = 0.05
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 192.8 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/08_water_cup.png" width="100%" 
alt="User instruction: Pick up a paper cup filled with water.
[sep]'''
Estimated characteristics:
m: 250g
µ: 0.6
k: 200 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 75.0
initial_force = slip_threshold = 4.08
additional_closure = 2.0
additional_force_increase = 0.4
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 373.2 N/m" onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/09_noodles.png" width="100%" 
                        alt="User instruction: Pick up a plastic bag containing noodles.
[sep]'''
Estimated characteristics:
m: 500g
µ: 0.4
k: 300 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 90.0
initial_force = slip_threshold = 12.3
additional_closure = 5.0
additional_force_increase = 0.15
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 4324. N/m" 
                        onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/10_avocado.png" width="100%"
                            alt=" User instruction: Pick up the avocado. 
[sep]'''
Estimated characteristics:
m: 200g
µ: 0.5
k: 500 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 60.0
initial_force = slip_threshold = 3.92
additional_closure = 2.0
additional_force_increase = 1.0
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 298.7 N/m"
                            onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/11_spray.png" width="100%" 
alt="User instruction: Pick up a plastic bottle containing water.
[sep]'''
Estimated characteristics:
m: 500g
µ: 0.4
k: 150 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 48.0
initial_force = slip_threshold = 12.2
additional_closure = 2.0
additional_force_increase = 0.03
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 1383. N/m" onclick="populateDemo(this);">
                    </div>
                    <div class="col-md-2 col-sm-2 col-xs-2 px-1">
                        <img src="videos/12_rice.png" width="100%" 
                        alt="User instruction: Pick up a plastic bag containing rice.
[sep]'''
Estimated characteristics:
m: 1000g
µ: 0.5
k: 200 N/m
'''

from magpie.gripper import Gripper
G = Gripper()
G.reset_parameters()

goal_aperture = 80.0
initial_force = slip_threshold = 19.6
additional_closure = 5.0
additional_force_increase = 1.0
k = G.grasp(goal_aperture, slip_threshold, additional_closure, additional_force_increase)

print(k)
## k: 6192. N/m" onclick="populateDemo(this);">
                    </div>
                </div>
                
            </div>
            <div class="col-md-1"></div>
        </div>

        

        <div class="row">
            <div class="col-2"></div>
            <div class="col-md-8">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Large language models (LLMs) can provide rich
                    physical descriptions of most worldly objects, allowing robots
                    to achieve more informed and capable grasping. We leverage
                    LLMs' common sense physical reasoning and code-writing
                    abilities to infer an object's physical characteristics—mass m,
                    friction coefficient µ, and spring constant k—from a semantic
                    description, and then translate those characteristics into an
                    executable adaptive grasp policy. Using a two-finger gripper with a 
                    built-in depth camera that can control its torque by limiting 
                    motor current, we demonstrate that LLM-parameterized but 
                    first-principles grasp policies outperform both traditional 
                    adaptive grasp policies and direct LLM-as-code policies on a custom 
                    benchmark of 12 delicate and deformable items including food, produce, 
                    toys, and other everyday items, spanning two orders of magnitude in 
                    mass and required pick-up force. We then improve property estimation 
                    and grasp performance on variable size objects with model finetuning 
                    on property-based comparisons and eliciting such comparisons 
                    via chain-of-thought prompting.
                     We also demonstrate how
                    compliance feedback from <span class="dg">DeliGrasp</span> policies can aid in downstream tasks such as measuring produce ripeness.
                </p>
            </div>
            <div class="col-2"></div>
        </div>

        <div class="row">
            <div class="col-2"></div>
            <div class="col-md-8">
                <h3>
                    Approach Overview
                </h3>
                <p style="text-align:center;">
                    <image src="img/dg_overview.png" class="img-responsive">
                </p>
                <p class="text-justify">
                    Large language models (LLMs) are able to supervise robot
                    control in manipulation across high-level step-by-step
                    task planning, low-level motion planning, and determining 
                    grasp positions conditioned on a given object's 
                    semantic properties. These methods inherently assume that the acts of “picking”
                    and “placing” are straightforward tasks, and cannot acount for
                    contact-rich manipulation tasks, such as
                    grasping a paper airplane, deformable plastic
                    bags containing dry noodles, or ripe produce. <br><br>
                    In this work, we propose <span class="dg">DeliGrasp</span>, which leverages LLMs' .
                    common-sense physical reasoning 
                    and code-writing abilities to infer the physical characteristics of gripper-object interactions, 
                    including mass, spring constant, and friction, to obtain grasp policies
                    for these kinds of delicate and deformable objects. We formulate an adaptive grasp controller
                    with slip detection derived from the inferred characteristics,
                    endowing LLMs embodied with any current-controllable
                    gripper with adaptive, open-world grasp skills for objects
                    spanning a range of weight, size, fragility, and compliance.
                </p>
            </div>
            <div class="col-2"></div>

        </div>
        <div class="row">
            <div class="col-2"></div>
            <div class="col-md-8">
                <h3>
                    Adaptive Grasp Policies
                </h3>
                <p style="text-align:center;">
                    <image src="img/fbd.png" class="img-responsive w-50">
                </p>
                <p class="text-justify">
                    The minimum grasp force required to pick an object up is
                    bounded between object slip acceleration and gripper upwards acceleration (2.5 m/s<sup>2</sup> for the UR5 robot arm), 
                    given an object's mass, m, and friction coefficient, µ.
                    <p style="text-align:center;">
                        <image src="img/bounds.png" class="img-responsive w-50">
                    </p>

                    Assuming a highly capable reasoning agent can estimate these two values,
                    we can define a closed-loop controller to achieve a minimally-deforming grasp:
                    increasing gripper output force F<sub>out</sub> and decreasing gripper
                    aperture <i>x</i> until sensing a contact force F<sub>c</sub> greater than
                    the target F<sub>min</sub>. To determine the gain terms, ∆F<sub>out</sub>
                    and ∆<i>x</i>, i.e. how fast we close the gripper and ratchet up
                    force, the controller utilizes an agent-determined k and ∆x to
                    compute ∆F<sub>out</sub> = <i>c</i> · <i>k</i>∆<i>x</i> (manual dampening
                    constant <i>c</i> = 0.1).
                </p>



                <p class="text-justify">
                    We task an LLM (GPT-4) with predicting these quantities for an arbitrary object. 
                    To generate grasp policies, we leverage a
                    dual-prompt structure similar to that of Language to Rewards, 
                    with an initial grasp “descriptor” prompt which estimates
                    object characteristics and special accommodations, if needed, from
                    the input object description. The “descriptor” prompt produces a 
                    structured description, which the subsequent “coder”
                    prompt translates into an executable Python grasp policy that
                    modulates gripper compliance, force, and aperture according
                    to the controller described above.
                </p>
            </div>
            <div class="col-md-2"></div>
        </div>


        <div class="row" id="demo">
            <div class="col-md-2"></div>
            <div class="col-md-8 col-xs-12">
                <h3>
                    Results
                </h3>
                <p>
                <p class="text-justify">
We test <span class="dg">DeliGrasp</span> on a UR5 robot
arm and a MAGPIE gripper looking top-down on a table
with a palm-integrated Intel RealSense D-405 camera against
a dataset of 12 delicate and deformable objects. 

                    We compare our method against 5 baselines:
                    1) in-place adaptive grasping with 2N and 10N grasp force thresholds,
                    2) in-motion adaptive grasping with 0.5N and 1.5N initial force,
                    3) a direct estimation baseline
                    in which <span class="dg">DeliGrasp</span> directly estimates the parameters of the adaptive grasping algorithm, contact force, force gain, and aperture gain,
                    4) a perception-informed baseline, where the gripper closes to an visually-determined object device-width, and
                    5) a traditional force-limited baseline, where the gripper closes until it cannot output any more force (set to 4 N).
                    We also include two additional <span class="dg">DeliGrasp</span> configurations: 1) with
                    PhysObjects finetuning and 2) with PhysObjects finetuning and chain-of-thought prompting.
                    <br>
                    <br>
                    As shown below, <span class="dg">DeliGrasp</span> performs equivalently or better than the baselines
                    on 10/12 objects and outperforms the baselines outright on 5/12 objects. 
                    Where force-limited grasps deform objects, and visually-informed grasps slip, <span class="dg">DeliGrasp</span> 
                    is successfully picks up objects with minimal deformation. While the direct estimation baseline is closer in performance, 
                    we observe higher volatility in estimated parameters, due to a lack 
                    of common-sense physical grounding, and thus, lower reliability and interpretability.
                    While the traditional adaptive grasping methods are more successful, particularly the "In Motion"
                    strategy, traditional methods are not as versatile as <span class="dg">DeliGrasp</span>
                    and are further dependent on their expert-tuned parameters for performance.
                    "In Motion" and "In Place" strategies with lower force settings are more successful
                    on lighter objects and the strategies with higher force settings are more successful
                    on the heavier objects. And all traditional methods crush highly delicate and light
                    objects like the raspberry. We conclude that it is the LLM's common
                    sense reasoning that enables such a dynamic grasping range in object mass and stiffness.
                </p>
            </div>
            <div class="col-2"></div>
        </div>

        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8 text-center px-0">
                    <image width="100%" src="img/deli_data_tab.png" class="img-responsive">
            </div>
            <div class="col-md-2"></div>

        </div>

        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">

                <p class="text-justify">
                    <br>
                    <span class="dg">DeliGrasp</span> failures are primarily slip failures, as the simple controller is not robust to non-linearly and/or highly compliant objects such
                    as the bag of noodles, bag of rice, spray bottle, and stuffed animal. Deforming failures did not occur, despite occasional mass overestimations,
                    because the applied force goalpoint, F<sub>min</sub>, is set to the estimated object's slip force rather than its maximum force. We show some of these failures below.
                    <div class="row">
                        <div class="col">
                            <button type="button" class="collapsible">Noodles, rice, bottle, stuffed animal.</button>
                            <div class="content">
                                <div class="row">
                                    <div class="col-3 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/fail/noodle_fail.mp4" type="video/mp4">
                                        </video>
                                    </div>      
                                    <div class="col-3 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/12_rice.mp4" type="video/mp4">
                                        </video>
                                    </div>       
                                    <div class="col-3 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/fail/spray_fail.mp4" type="video/mp4">
                                        </video>
                                    </div>      
                                    <div class="col-3 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/fail/stuffed_animal_fail.mp4" type="video/mp4">
                                        </video>
                                    </div>      
                                </div>
                            </div>      
                        </div>
                      </div>     
<br>
                    We also show how the compliance feedback from <span class="dg">DeliGrasp</span> 
                    policies enables downstream tasks such as measuring produce ripeness. In the below sequence, we
                    show how <span class="dg">DeliGrasp</span> performs semantic segmentation on a bin of avocados, generates different grasp policies for 
                    different actions "checking for ripeness" vs. "picking up", and uses the measured compliance to pick
                    an appropriate avocado for "guacamole today".

                </p>
            </div>
            <div class="col-md-2"></div>
        </div>
<!-- break container -->
</div>

<section class="hero is-light has-background-light is-small">
    <div class="hero-body car_color">
        <div class="container has-text-centered">
        <div id="results-carousel" class="carousel results-carousel">

            <div class="item item-mask">
                <h4 class="title is-3">Semantic Segmentation</h4>
                    <img src="img/sem_seg.png" width="44%" height="40%" alt="User instruction: Pick up the paper airplane." onclick="populateDemo(this);">
            </div>           
            
            <div class="item">
            <h4 class="title is-3"><span class="dg">Adjusted DeliGrasp</span> Policies</h4>
                <div class="has-text-justified">
                    <pre><code class="python"> ''' Estimated characteristics:
m: 200g
µ: 0.5
k: 500 N/m
F_min:  3.92 N

This grasp sets the initial force to a different initial force 0.5 Newton because of requiring gentle pressing to assess ripeness without causing indentations.
'''
                        </code></pre>            
                </div>
            </div>

            <div class="item item-steve">
                <h4 class="title is-3">Measuring <i>k</i></h4>
                <video width="50%" height="50%" poster="" id="steve" autoplay muted loop playsinline>
                    <source src="videos/ripeness/stacked.mp4"
                            type="video/mp4">
                </video>
            </div>

            <div class="item item-coffee">
                <h4 class="title is-3">LLM Ripeness Reasoning</h4>
                <div class="has-text-justified">
                <pre><code class="python">''' User: Given this image of avocados and their corresponding spring constants, pick out the best avocado for guacamole today.'''
                    
''' GPT-4V: Unfortunately, the image has a resolution that does not allow for a detailed inspection of the avocado's color. Avocado with spring constant k<sub>1</sub> would be the best choice for guacamole today as it would be the softest and most ripe of the three, which is desirable for making guacamole.'''
                                            </code></pre>            
                </div>

            </div>

            <div class="item item-coffee">
                <h4 class="title is-3">Pick <i>k</i><sub>1</sub></h4>
                <video width="50%" height="50%" poster="" id="coffee" autoplay muted loop playsinline>
                <source src="videos/ripeness/k1p.mp4"
                        type="video/mp4">
                </video>
            </div>

        </div>
        </div>
    </div>  
</section>

<!-- resume container -->
<div class="container">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8" id="faqs">
                <h3>
                      FAQs
                  </h3>
                <p class="text-justify">
                    <p><b>
                        How does this differ from Language to Rewards and Code as Policies?
                         </b></p>  <p>
                        <span class="dg">DeliGrasp</span>'s primary function is the
                        estimation of object mass, friction, and compliance, and modulating the computed 
                        grasp force depending on the high-level task description. We pair it with an
                        adaptive grasping algorithm derived from traditional adaptive grasp controllers and tailored for these
                        estimated characteristics. <span class="dg">DeliGrasp</span> parameterizes
                        low-level contact rich manipulation, rather than directly design low-level motion
                        with reward functions or pre-defined robot primitive skills.
                    </p>

                    </p> <p><b>
                        How does the controller compare to a classic adaptive grasping methods?
                    </b></p>  <p>
                    <ol>
                        <li> DeliGrasp outperforms classical methods on the evaluated delicate objects. </li>
                        <li> Classical methods are often customized for specific gripper hardware or suites of sensors, whereas ours can be adapted to any current-controllable end-effector. </li>
                        <li> Our algorithm is a simple closed-loop feedforward controller because it relies on LLM-estimated terms which reduce controller complexity.</li>
                        <li> Many methods employ in-motion slip detection, which <span class="dg">DeliGrasp</span> is not capable of.</li>
                    </ol>
                    </p>

                </p> <p><b>
                    What else can <span class="dg">DeliGrasp</span> pick up?
                </b></p>  <p>
                    <div class="row">
                        <div class="col">
                            <button type="button" class="collapsible">Eggs, pastries, and potato chips.</button>
                            <div class="content">
                                <div class="row">
                                    <div class="col-4 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/4fun/egg.mp4" type="video/mp4">
                                        </video>
                                    </div>      
                                    <div class="col-4 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/4fun/pastry.mp4" type="video/mp4">
                                        </video>
                                    </div>       
                                    <div class="col-4 text-center px-1">
                                        <video width="75%" height="75%"  autoplay muted loop playsinline>
                                            <source src="videos/4fun/chip.mp4" type="video/mp4">
                                        </video>
                                    </div>      
                                </div>
                            </div>      
                        </div>
                      </div>     
                </p>

                    </p> <p><b>
                        But can <span class="dg">DeliGrasp</span> pick up deli meats?
                    </b></p>  <p>
                        <div class="row">
                            <div class="col">
                                <button type="button" class="collapsible">Ironically, not really.</button>
                                <div class="content">
                                    <div class="row">
                                        <div class="col text-center">
                                            <video width="25%" height="25%"  autoplay muted loop playsinline>
                                                <source src="videos/4fun/pastrami_fail.mp4" type="video/mp4">
                                            </video>
                                        </div>
                                    </div>
                                </div>      
                            </div>
                          </div>
                    </p>



            </div>
            <div class="col-md-2"></div>
          </div>



        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <h3>
                      Prompts
                  </h3>
                <p class="text-justify">
                    <span class="dg">DeliGrasp</span>: 
                    <a href="./assets/prompts/dg_descriptor.txt">Grasp Descriptor</a> |
                    <a href="./assets/prompts/dg_descriptor_cot.txt">Grasp Descriptor with CoT Prompting</a> |
                    <a href="./assets/prompts/dg_coder.txt">Grasp Coder</a>
                </p>
            </div>
            <div class="col-md-2"></div>
          </div>


        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <h3>
                    BibTeX Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly style="height: 135px;">
@InProceedings{xie_deligrasp_24,
    title = 	 {DeliGrasp: Inferring Object Properties with LLMs for Adaptive Grasp Policies},
    author =       {Xie, William and Valentini, Maria and Lavering, Jensen and Correll, Nikolaus},
    booktitle = 	 {Proceedings of The 8th Conference on Robot Learning},
    pages = 	 {1290--1309},
    year = 	 {2024},
    publisher =    {PMLR},
    url = 	 {https://proceedings.mlr.press/v270/xie25a.html},
    }
                           </textarea>
                </div>
            </div>
            <div class="col-md-2"></div>
        </div>

        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    The authors would like to thank Eric Xue, Enora Rice, Shivendra Agrawal, James Watson, and Max Conway for their feedback and support. <br><br>
                    The website template is adapted from <a href="https://language-to-reward.github.io/">Language to Rewards</a> and <a href="https://progprompt.github.io">ProgPrompt</a>.
                </p>
            </div>
            <div class="col-md-2"></div>
        </div>
    </div>
</body>

<script>

    timeoutIds = [];

    function populateDemo(imgs) {
        // Get the expanded image
        var expandImg = document.getElementById("expandedImg");
        // Get the image text
        var imgText = document.getElementById("imgtext");
        var answer = document.getElementById("answer");

        // Use the same src in the expanded image as the image being clicked on from the grid
        expandImg.src = imgs.src.replace(".png", ".mp4");
        var video = document.getElementById('demo-video');
        // or video = $('.video-selector')[0];
        video.pause()
        video.load();
        video.play();
        video.removeAttribute('controls');
        
        console.log(expandImg.src);
        // Use the value of the alt attribute of the clickable image as text inside the expanded image
        var qa = imgs.alt.split("[sep]");
        imgText.innerHTML = qa[0];
        answer.innerHTML = "";
        // Show the container element (hidden with CSS)
        expandImg.parentElement.style.display = "block";
        for (timeoutId of timeoutIds) {
            clearTimeout(timeoutId);
        }
        typeWriter(qa[1], 0, qa[0]);
    }

    // function typeWriter(div, txt, i, q) {
    function typeWriter(txt, i, q) {
        var imgText = document.getElementById("imgtext");
        if (imgText.innerHTML == q) {
            if (i < txt.length) {
                if (txt.charAt(i) == "\\") {
                    answer.innerHTML += "\n";
                    // div.innerHTML += "\n";
                    i += 1;
                } else {
                    answer.innerHTML += txt.charAt(i);
                    // div.innerHTML += txt.charAt(i);
                }
                i++;
                timeoutIds.push(setTimeout(typeWriter, 5, txt, i, q));
            }
            else {
                hljs.highlightAll();
            }
        }
        i = 0
    }

    var myCarousel = document.querySelector('#myCarousel')
    var carousel = new bootstrap.Carousel(myCarousel, {interval: 500, wrap: true})
    var slides = document.querySelectorAll('.carousel .carousel-item')

    slides.forEach((el) => {
        // number of slides per carousel-item
        const minPerSlide = slides.length
        let next = el.nextElementSibling
        for (var i=1; i<minPerSlide; i++) {
            if (!next) {
                // wrap carousel by using first child
                next = slides[0]
            }
            let cloneChild = next.cloneNode(true)
            el.appendChild(cloneChild.children[0])
            next = next.nextElementSibling
        }
})

</script>
</html>


<!-- 
cutting this cursed carousel
                  </p> <p><b>
                    That's not really a robot at all, is it? I smell something real avian going on.
                </b></p>  <p>
                    <div class="row">
                        <div class="col">
                            <button type="button" class="collapsible">Click for the truth (REAL).</button>
                            <div class="content">
                                <div class="row">
                                    <div class="col text-center">
    <section class="hero is-light has-background-light is-small">
        <div class="hero-body car_color">
            <div class="container has-text-centered">
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-steve">
                <h4 class="title is-3">Pick up the avocado</h4>
                <video width="50%" height="50%" poster="" id="steve" autoplay muted loop playsinline>
                    <source src="videos/10_avocado.mp4"
                            type="video/mp4">
                </video>
                </div>
                <div class="item item-coffee">
                <h4 class="title is-3">Pick up a raspberry</h4>
                <video width="50%" height="50%" poster="" id="coffee" autoplay muted loop playsinline>
                    <source src="videos/04_raspberry.mp4"
                            type="video/mp4">
                </video>
                </div>
                <div class="item item-blueshirt">
                <h4 class="title is-3">Pick up an egg.</h4>
                <video width="50%" height="50%" poster="" id="blueshirt" autoplay muted loop playsinline>
                    <source src="videos/4fun/egg.mp4"
                            type="video/mp4">
                </video>
                </div>
                <div class="item item-mask">
                <h4 class="title is-3">Pick up a potato chip.</h4>
                <video width="50%" height="50%" poster="" id="mask" autoplay muted loop playsinline>
                    <source src="videos/4fun/chip.mp4"
                            type="video/mp4">
                </video>
                </div>
                <div class="item item-mask">
                <h4 class="title is-3">Pick up a pastry.</h4>
                <video width="50%" height="50%" poster="" id="mask" autoplay muted loop playsinline>
                        <source src="videos/4fun/pastry.mp4"
                                type="video/mp4">
                    </video>
                </div>
                <div class="item item-mask">
                <h4 class="title is-3">Pick up a paper airplane.</h4>
                <video width="50%" height="50%" poster="" id="mask" autoplay muted loop playsinline>
                        <source src="videos/01_plane.mp4"
                                type="video/mp4">
                    </video>
                </div>
            </div>
            </div>
        </div>  
    </section>
  
 -->